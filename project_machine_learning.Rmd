
#I imported all the necessary package to predect the manner the group of people did the excercice.
rm(list=ls())
library(knitr)
library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrplot)
set.seed(12345)
#Then I uploaded data to my rstudio 
UrlTrain <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
UrlTest  <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training<-read.csv(url(UrlTrain))
testing<- read.csv(url(UrlTest))
inTrain <- createDataPartition(training$classe, p = 0.7, list = FALSE)
TrainSet<-training[inTrain,]
TestSet<-training[-inTrain,]
dim(TrainSet)
dim(TestSet)
NZV<- nearZeroVar(TrainSet)
TrainSet<- TrainSet[,-NZV]
TestSet<-TestSet[,-NZV]
dim(TrainSet)
dim(TestSet)
# The data seems hasa large number of columns in the dataset, I checked if there are missing data in it.Then,
I cleaned th data and saw how variables are correlated between each other.
AllNA<- sapply(TrainSet,function(x)mean(is.na(x)))> 0.95
ALLNA
TrainSet<-TrainSet[,AllNA==FALSE]
TestSet<-TestSet[,AllNA==FALSE]
dim(TrainSet)
dim(TestSet)
TrainSet <- TrainSet[, -(1:5)]
TestSet  <- TestSet[, -(1:5)]
dim(TrainSet)
dim(TestSet)
corrMatrix<- cor(TrainSet[,-54])
corrplot(corrMatrix,order="FPC",method="color", type="lower",tl.cex=0.8,tl.col=rgb(0,0,0))
#I will use prediction models now with three methods and the one with higher accurancy will be the chosen one.In order to visualise the accurancy I will use a plot of the confusion matrix
#RANDOM FOREST MODEL
set.seed(12345)
tcontrolRF<- trainControl(method = "cv", number = 3,verboseIter = FALSE)
modFitRandForest<- train(classe~ ., data=TrainSet,method="rf",trControl=tcontrolRF )
modFitRandForest$finalModel
predictRandForest <- predict(modFitRandForest, newdata=TestSet)
predictRandForest
confMatRandForest <- confusionMatrix(predictRandForest, TestSet$classe)
confMatRandForest
# The accurancy here is 0.9964 .
# method2: decision tree
set.seed(32165)
modFitDecTree <- rpart(classe ~ ., data=TrainSet, method="class")
fancyRpartPlot(modFitDecTree)
predictDecTree <- predict(modFitDecTree, newdata=TestSet, type="class")
predictDecTree
confMatDecTree <- confusionMatrix(predictDecTree, TestSet$classe)
confMatDecTree
plot(confMatDecTree$table, col = confMatDecTree$byClass, 
     main = paste("Decision Tree - Accuracy =",
                  round(confMatDecTree$overall['Accuracy'], 4)))
# The accurancy here is  0.7368 .
# method3 :Genereliized Boosted Model
set.seed(32165)
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
modFitGBM  <- train(classe ~ ., data=TrainSet, method = "gbm",
                    trControl = controlGBM, verbose = FALSE)
modFitGBM$finalModel
predictGBM <- predict(modFitGBM, newdata=TestSet)
predictGBM
confMatGBM <- confusionMatrix(predictGBM, TestSet$classe)
confMatGBM
plot(confMatGBM$table, col = confMatGBM$byClass, 
     main = paste("GBM - Accuracy =", round(confMatGBM$overall['Accuracy'], 4)))
		 # The accurancy here is  0.9854 .
 So I chose the first model using random forest model which has the higher accurancy with value of 0.9964
